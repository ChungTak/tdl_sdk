#include "object_detection/mobiledetv2.hpp"

#include "utils/tdl_log.hpp"
static const float STD_R = (255.0 * 0.229);
static const float STD_G = (255.0 * 0.224);
static const float STD_B = (255.0 * 0.225);
static const float MODEL_MEAN_R = 0.485 * 255.0;
static const float MODEL_MEAN_G = 0.456 * 255.0;
static const float MODEL_MEAN_B = 0.406 * 255.0;

MobileDetV2::MobileDetV2(int num_classes) {
  // TODO:
  num_cls_ = num_classes;

  net_param_.pre_params.scale[0] = 1.0 / STD_R;
  net_param_.pre_params.scale[1] = 1.0 / STD_G;
  net_param_.pre_params.scale[2] = 1.0 / STD_B;
  net_param_.pre_params.mean[0] = MODEL_MEAN_R / STD_R;
  net_param_.pre_params.mean[1] = MODEL_MEAN_G / STD_G;
  net_param_.pre_params.mean[2] = MODEL_MEAN_B / STD_B;
  net_param_.pre_params.dst_img_format = IMAGE_FORMAT_RGB_PLANAR;
  net_param_.pre_params.keepAspectRatio = true;
}

MobileDetV2::~MobileDetV2() {
  // TODO:
}

int32_t MobileDetV2::onModelOpened() {
  const auto &input_layer = net_->getInputNames()[0];
  auto input_shape = net_->getTensorInfo(input_layer).shape;
  int input_h = input_shape[2];
  int input_w = input_shape[3];

  const int min_level = 3;
  const int max_level = 7;
  const int num_scales = 3;
  const std::vector<std::vector<float>> aspect_ratios = {
      {1.0, 1.0}, {1.4, 0.7}, {0.7, 1.4}};
  const float anchor_scale = 4.0;
  const std::vector<int> strides = {8, 16, 32, 64, 128};

  int num_per_grid = num_scales * aspect_ratios.size();

  std::vector<std::string> out_names = net_->getOutputNames();
  class_out_names_.clear();
  bbox_out_names_.clear();
  obj_max_names_.clear();
  strides_.clear();

  int un_named_tensor = 0;
  for (size_t j = 0; j < out_names.size(); j++) {
    if (out_names[j].find("class_stride") == std::string::npos &&
        out_names[j].find("box_stride") == std::string::npos) {
      printf("found not named tensor:%s\n", out_names[j].c_str());
      un_named_tensor += 1;
    }
  }
  if (un_named_tensor > 0) {
    for (size_t i = 0; i < out_names.size(); i++) {
      TensorInfo oinfo = net_->getTensorInfo(out_names[i]);
      int feat_w = oinfo.shape[2];
      int feat_h = oinfo.shape[1];
      int channel = oinfo.shape[3];
      int stridew = input_w / feat_w;
      int strideh = input_h / feat_h;
      if (stridew != strideh) {
        LOGE("stride not equal,stridew:%d,strideh:%d,featw:%d,feath:%d\n",
             stridew, strideh, feat_w, feat_h);
        assert(0);
      }
      if (channel == num_cls_ * num_per_grid) {
        // class branch
        class_out_names_[stridew] = out_names[i];
      } else if (channel == 4 * num_per_grid) {
        // box branch
        bbox_out_names_[stridew] = out_names[i];
      } else if (channel == num_per_grid) {
        // obj max branch
        obj_max_names_[stridew] = out_names[i];
      } else {
        LOGE("unexpected branch,channel:%d,name:%s", channel,
             out_names[i].c_str());
        assert(0);
      }
      strides_.push_back(stridew);
    }
    std::sort(strides_.begin(), strides_.end());  // from less to more
  } else {
    strides_ = {8, 16, 32, 64, 128};
    class_out_names_ = {{8, "class_stride_8"},
                        {16, "class_stride_16"},
                        {32, "class_stride_32"},
                        {64, "class_stride_64"},
                        {128, "class_stride_128"}};

    obj_max_names_ = {{8, "class_stride_8_obj_max"},
                      {16, "class_stride_16_obj_max"},
                      {32, "class_stride_32_obj_max"},
                      {64, "class_stride_64_obj_max"},
                      {128, "class_stride_128_obj_max"}};

    bbox_out_names_ = {{8, "box_stride_8"},
                       {16, "box_stride_16"},
                       {32, "box_stride_32"},
                       {64, "box_stride_64"},
                       {128, "box_stride_128"}};
  }

  return 0;
}

void MobileDetV2::decodeDetsForTensor(const int stride,
                                      std::vector<float> &dets) {
  TensorInfo cls_info = net_->getTensorInfo(class_out_names_[stride]);
  TensorInfo bbox_info = net_->getTensorInfo(bbox_out_names_[stride]);
  TensorInfo obj_max_info = net_->getTensorInfo(obj_max_names_[stride]);

  std::string input_tensor_name = net_->getInputNames()[0];
  TensorInfo input_tensor = net_->getTensorInfo(input_tensor_name);

  for (size_t obj_index = 0; obj_index < class_tensor_size; obj_index++) {
    int8_t score_logits = *(logits + obj_index);
    if (score_logits < quant_thresh) {
      continue;
    }
    int8_t objectness_logits = *(objectness + obj_index);
    if (unlikely(objectness_logits >= quant_thresh)) {
      // create detection if any object exists in this grid
      size_t score_index = obj_index * m_model_config.num_classes;
      size_t end = score_index + m_model_config.num_classes;
    }
  }

  return;
}
int32_t MobileDetV2::outputParse(
    const std::vector<std::shared_ptr<BaseImage>> &images,
    std::vector<std::shared_ptr<ModelOutputInfo>>&out_datas) {
  std::string input_tensor_name = net_->getInputNames()[0];
  TensorInfo input_tensor = net_->getTensorInfo(input_tensor_name);
  uint32_t input_width = input_tensor.shape[3];
  uint32_t input_height = input_tensor.shape[2];
  float input_width_f = float(input_width);
  float input_height_f = float(input_height);
  float inverse_th = std::log(model_threshold_ / (1 - model_threshold_));
  LOGI("outputParse,batch size:%d,input shape:%d,%d,%d,%d", images.size(),
       input_tensor.shape[0], input_tensor.shape[1], input_tensor.shape[2],
       input_tensor.shape[3]);

  float inverse_th = std::log(model_threshold_ / (1 - model_threshold_));

  std::stringstream ss;
  for (uint32_t b = 0; b < (uint32_t)input_tensor.shape[0]; b++) {
    uint32_t image_width = images[b]->getWidth();
    uint32_t image_height = images[b]->getHeight();

    std::vector<cvtdl_object_t> vec_obj;
    std::map<int, std::vector<cvtdl_bbox_t>> lb_boxes;
    for (size_t i = 0; i < strides_.size(); i++) {
      int stride = strides_[i];
      std::string cls_name = class_out_names_[stride];
      std::string bbox_name = bbox_out_names_[stride];
      std::string obj_max_name = obj_max_names_[stride];

      TensorInfo cls_info = net_->getTensorInfo(cls_name);
      TensorInfo bbox_info = net_->getTensorInfo(bbox_name);
      TensorInfo obj_max_info = net_->getTensorInfo(obj_max_name);

      int8_t obj_quant_thresh =
          static_cast<int8_t>(round(inverse_th / obj_max_info.qscale));

      int8_t *cls_data =
          reinterpret_cast<int8_t *>(cls_info.sys_mem) +
          b * cls_info.shape[1] * cls_info.shape[2] * cls_info.shape[3];
      int8_t *bbox_data =
          reinterpret_cast<int8_t *>(bbox_info.sys_mem) +
          b * bbox_info.shape[1] * bbox_info.shape[2] * bbox_info.shape[3];
      int8_t *obj_max_data = reinterpret_cast<int8_t *>(obj_max_info.sys_mem) +
                             b * obj_max_info.shape[1] * obj_max_info.shape[2] *
                                 obj_max_info.shape[3];

      int num_anchors = obj_max_info.shape[2] * obj_max_info.shape[3];
      for (int anchor_idx = 0; anchor_idx < num_anchors; anchor_idx++) {
        if (obj_max_data[anchor_idx] < obj_quant_thresh) {
          continue;
        }
        int score_index = anchor_idx * num_cls_;
        int score_end = score_index + num_cls_;
        for (int score_idx = score_index; score_idx < score_end; score_idx++) {
          if (cls_data[score_idx] < score_quant_thresh) {
            continue;
          }
        }
        int8_t *cls_ptr = cls_data + score_index * cls_info.shape[1];
        int8_t *bbox_ptr = bbox_data + anchor_idx * bbox_info.shape[1];
        int8_t *obj_max_ptr = obj_max_data + anchor_idx;

        decodeDetsForTensor(stride, anchor_idx, cls_ptr, bbox_ptr, obj_max_ptr);
      }
    }
  }
}
